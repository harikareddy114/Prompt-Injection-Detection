{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Worksheet 2: DGA Detection using Machine Learning - Answers\n",
    " \n",
    "This worksheet covers concepts covered Supervised Learning. Train and evaluate a classification model using [sklearn](http://scikit-learn.org/stable/). It should take no more than 40-60 minutes to complete.\n",
    "\n",
    "This notebook is a step-by-step guide on how to detect domains that were generated using \"Domain Generation Algorithm\" (DGA). We will walk you through the process of creating a decision tree classifier which you will use to determine whether a given domain is legit or not. Once you have implemented the classifier, the worksheet will walk you through evaluating your model and getting interpretable results for predictions.\n",
    "\n",
    "\n",
    "1. **Feature Engineering** - Previously completed\n",
    "2. **Machine Learning Classification** - predict whether a domain is legit or not using a Decision Tree Classifier\n",
    "\n",
    "## Import the Libraries\n",
    "For this exercise, we will be using:\n",
    "* Pandas (http://pandas.pydata.org/pandas-docs/stable/)\n",
    "* Numpy (https://docs.scipy.org/doc/numpy/reference/)\n",
    "* Matplotlib (http://matplotlib.org/api/pyplot_api.html)\n",
    "* Scikit-learn (http://scikit-learn.org/stable/documentation.html)\n",
    "* [Lime](https://github.com/marcotcr/lime)\n",
    "* [SHAP](https://shap.readthedocs.io/en/latest/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Load Libraries - Make sure to run this cell!\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import feature_extraction, tree, model_selection, metrics\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image\n",
    "from IPython.display import display\n",
    "import pydotplus as pydot\n",
    "\n",
    "import lime\n",
    "import shap\n",
    "shap.initjs()\n",
    "\n",
    "import io\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Features and Labels\n",
    "\n",
    "If you got stuck in the Feature Engineering section, please simply uncomment the code below to load the feature matrix we prepared for you, so you can move on to train a Decision Tree Classifier."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#load full dataset\n",
    "df_final = pd.read_csv('../data/dga_features_final_df.csv')\n",
    "\n",
    "#If you didn't get a working dataset, uncomment this line\n",
    "#df_final = pd.read_csv('../data/our_data_dga_features_final_df.csv')\n",
    "\n",
    "df_final.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(df_final['isDGA'].value_counts())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the ```feature_matrix``` and ```target``` \n",
    "\n",
    "- In statistics and machine learning, the ```feature_matrix``` is often referred to as ```X```\n",
    "- The target vector that contains the labels for each row is called ```y``` \n",
    "- In sklearn both the features and targets can either be a pandas DataFrame/Series or numpy array/vector respectively (can't be lists!)\n",
    "\n",
    "Tasks:\n",
    "- Create a vector that contains the **target**s\n",
    "- Create the **feature_matrix** that has only the features and not the targets "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a vector named 'target' \n",
    "\n",
    "Assign the **isDGA** column to a pandas Series named **target**. The ```target``` variable should be a vector (1 dimension) of the correct (ground truth) answer for each row of the dataset. For this DGA use case, each item will be a string that indicates whether the domain was **dga** or **legit**. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "target = # your code here\n",
    "target.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Feature Matrix\n",
    "\n",
    "In order to train a model you have to separate the features from the targets. Create the ```feature_matrix``` (pandas dataframe) by dropping the **isDGA** column from ```df_final```."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "feature_matrix = df_final.drop(# your code here)\n",
    "feature_matrix.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creata a list of our feature names for plotting later and if we need to pull the features again from the full dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "feature_names = feature_matrix.columns.to_list()\n",
    "print(feature_names)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test-Train split\n",
    "\n",
    "Split (the dataset) your ```feature_matrix``` and ```target``` into **train** and **test** subsets using sklearn [model_selection.train_test_split](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)\n",
    "\n",
    "Output of the split should be 2 complete sets of data (**train** and **test** that are still separated into features and labels: \n",
    " - **feature_matrix_train**: 75% of the feature matrix (data)\n",
    " - **feature_matrix_test**: the remaining 25% of the feature matrix\n",
    " - **target_train**: the labels for the train features\n",
    " - **target_test**: the labels for the test features"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "feature_matrix_train, feature_matrix_test, target_train, target_test = # Your code here...HERE,",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "feature_matrix_train.shape"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "feature_matrix_test.shape"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "target_train[1:5]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "target_test[1:5]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model and make a prediction\n",
    "\n",
    "Finally, we have prepared and split the data. Let's start classifying!!   \n",
    "\n",
    "Tasks:\n",
    "-  Use the sklearn [tree.DecisionTreeClassfier()](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html), instantiate (create) a decision tree model with default parameters (we will tune these in the next lab).\n",
    "- Train this model using the ```feature_matrix_train``` and ```target_train``` data (you will need to call the **.fit()** method on the model to do this).\n",
    "-  Next, pull a few random rows from the data to spot check the predictions of the model against the true labels."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "d_tree_model = tree.DecisionTreeClassifier()  \n",
    "d_tree_model = d_tree_model.fit(# YOUR CODE HERE)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it! You trained the model. Now extract a row from the test set to see if the model can predict the correct answer by comparing it to the test target (ground truth). "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Extract a row from the test data\n",
    "\n",
    "row_number = 14\n",
    "row_feature = feature_matrix_test[row_number:row_number+1]\n",
    "\n",
    "# Make the prediction\n",
    "row_pred = d_tree_model.predict(row_feature)\n",
    "\n",
    "# pull out the ground truth for this row\n",
    "row_target = target_test[# YOUR CODE HERE]\n",
    "\n",
    "                                                    \n",
    "# print the results and the ground truth\n",
    "print('Predicted class:', row_pred)\n",
    "\n",
    "print('Ground truth class:', row_target)\n",
    "\n",
    "print('Accurate prediction?', row_pred == row_target)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make predictions on test set\n",
    "\n",
    "Make predictions for all your **test** data. This will be data that the model has not 'seen' before so we will use these predictions to evaluate how well the model can predict the correct answer on new data by calling a few different metrics functions.\n",
    "\n",
    "- Call the ```.predict()``` method on the model ```d_tree_model``` with your test data ```feature_matrix_test``` and store the results in a variable called ```test_predictions```. \n",
    "  \n",
    "- Then calculate the **accuracy** (and several other metris) using ```target_test``` (which are the true labels/ground truth) AND your models predictions on the test portion ```test_predictions``` as inputs. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# make predictions on all of the test data\n",
    "test_predictions = d_tree_model.predict(# YOUR CODE HERE)\n",
    "\n",
    "# print a sample of the predictions\n",
    "print(test_predictions[0:5])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the model as a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "filename = '../data/dga_decision_tree.sav'\n",
    "pickle.dump(d_tree_model, open(filename, 'wb'))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the model performance with metrics and visualizations\n",
    "\n",
    "## Print metrics\n",
    "Use sklearn [metrics.accuracy_score](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html) to calculate the model accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"Accuracy:\", metrics.accuracy_score(target_test, test_predictions))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(metrics.classification_report(# YOUR CODE HERE))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "conf_matrix = metrics.confusion_matrix(# YOUR CODE HERE,\n",
    "                                        labels=d_tree_model.classes_)\n",
    "\n",
    "disp = metrics.ConfusionMatrixDisplay(confusion_matrix=conf_matrix,\n",
    "                                       display_labels=d_tree_model.classes_)\n",
    "\n",
    "disp.plot(cmap='summer');"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) Visualizing your Tree\n",
    "As an optional step, you can actually visualize your tree.  The following code will generate a graph of your decision tree.  You will need graphviz (http://www.graphviz.org) and pydotplus (or pydot) installed for this to work. It should be there if you created your environment from our yml file. \n",
    "\n",
    "Run the cell below and then click on the image to enlarge it and see the details of each split in the tree."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "dot_data = io.StringIO() \n",
    "tree.export_graphviz(d_tree_model, out_file=dot_data, \n",
    "                     feature_names=feature_names,\n",
    "                    filled=True, rounded=True,  \n",
    "                    special_characters=True) \n",
    "\n",
    "graph = pydot.graph_from_dot_data(dot_data.getvalue()) \n",
    "Image(graph.create_png())\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explain a model\n",
    "Two methods for explaining a model. \n",
    "\n",
    "## Method 1: feature importance - impunity decrease\n",
    "\n",
    "In Sci-kit Learn tree (and other) models, feature importances are provided by the fitted attribute `feature_importances_` and they are computed as the mean and standard deviation of accumulation of the impurity decrease within each tree."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "importances = d_tree_model.feature_importances_\n",
    "\n",
    "d_tree_importances = pd.Series(importances, index=feature_names)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "d_tree_importances.plot.barh(ax=ax)\n",
    "ax.set_title(\"Feature importances using MDI\")\n",
    "ax.set_ylabel(\"Mean decrease in impurity\")\n",
    "fig.tight_layout()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2: Feature Importance using feature permutation\n",
    "\n",
    "Permutation feature importance overcomes limitations of the impurity-based feature importance: they do not have a bias toward high-cardinality features and can be computed on a left-out test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "result = permutation_importance(\n",
    "    d_tree_model, feature_matrix_test, target_test, n_repeats=10, random_state=42, n_jobs=2\n",
    ")\n",
    "\n",
    "perm_importances = pd.Series(result.importances_mean, index=feature_names)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "fig, ax = plt.subplots()\n",
    "perm_importances.plot.barh(yerr=result.importances_std, ax=ax)\n",
    "ax.set_title(\"Feature importances using permutation on full model\")\n",
    "ax.set_ylabel(\"Mean accuracy decrease\")\n",
    "fig.tight_layout()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 3: SHAP\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# explain all the predictions in the test set\n",
    "explainer = shap.KernelExplainer(d_tree_model.predict_proba, feature_matrix_train)\n",
    "shap_values = explainer.shap_values(feature_matrix_test)\n",
    "shap.force_plot(explainer.expected_value[0], shap_values[..., 0], feature_matrix_test)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explaining a specific prediction: SHAP\n",
    "In the example below, you can use SHAP to explain how a classifier arrived at its prediction.  Try running SHAP with the  classifier you've created and various rows to see how it functions. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# choose an item from the test set and print the values\n",
    "sample_number = 20\n",
    "print('true_label =', target_test.iloc[sample_number])\n",
    "feature_matrix_test.iloc[sample_number]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# choose an item from the test set and print the values\n",
    "sample_number = 20\n",
    "print('true_label =', target_test.iloc[sample_number])\n",
    "feature_matrix_test.iloc[sample_number]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explain a prediction: LIME\n",
    "Lime is similar to SHAP in that it can help us understand what features were used/influencial in the decision of a prediction. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import lime.lime_tabular\n",
    "explainer = lime.lime_tabular.LimeTabularExplainer(feature_matrix_train, \n",
    "                                                   feature_names=feature_names, \n",
    "                                                  class_names=d_tree_model.classes_, \n",
    "                                                   discretize_continuous=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the explanation for the same data point (row) from the test set that we used above."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "exp = explainer.explain_instance(feature_matrix_test.iloc[sample_number], \n",
    "                                 d_tree_model.predict_proba, \n",
    "                                 num_features=6)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "exp.as_list()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "exp.as_pyplot_figure()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "exp.show_in_notebook(show_table=True, show_all=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and evaluate more models\n",
    "Now that you've built a Decision Tree, let's try out two other classifiers and see how they perform on this data.  For this next exercise, create classifiers using:\n",
    "\n",
    "* Support Vector Machine\n",
    "* Random Forest\n",
    "* K-Nearest Neighbors (http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)  \n",
    "\n",
    "Once you've done that, run the various performance metrics to determine which classifier works best."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "random_forest_clf = RandomForestClassifier(n_estimators=10, \n",
    "                             max_depth=None, \n",
    "                             min_samples_split=2, \n",
    "                             random_state=0)\n",
    "\n",
    "random_forest_clf = random_forest_clf.fit(feature_matrix_train, target_train)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "random_forest_test_predictions = random_forest_clf.predict(feature_matrix_test)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"Accuracy:\", metrics.accuracy_score(target_test, random_forest_test_predictions))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(metrics.classification_report(target_test, random_forest_test_predictions))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "rf_conf_matrix = metrics.confusion_matrix(target_test, random_forest_test_predictions, labels=random_forest_clf.classes_)\n",
    "disp = metrics.ConfusionMatrixDisplay(confusion_matrix=rf_conf_matrix,\n",
    "                              display_labels=random_forest_clf.classes_)\n",
    "\n",
    "disp.plot(cmap='cividis');"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a SVM classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from sklearn import svm\n",
    "\n",
    "svm_classifier = svm.SVC()\n",
    "svm_classifier = svm_classifier.fit(feature_matrix_train, target_train)  "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make predictions on the test set"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "svm_test_predictions = # YOUR CODE HERE"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"SVM Accuracy:\", metrics.accuracy_score(# YOUR CODE HERE))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(metrics.classification_report(# YOUR CODE HERE))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "svm_conf_matrix = metrics.confusion_matrix(# YOUR CODE HERE)\n",
    "disp = metrics.ConfusionMatrixDisplay(# YOUR CODE HERE)\n",
    "\n",
    "disp.plot(cmap='magma');"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a K-Nearest Neighbors Classifier"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_clf = KNeighborsClassifier()\n",
    "knn_clf = # YOUR CODE HERE"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "knn_test_predictions = # YOUR CODE HERE"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"KNN Accuracy:\", # YOUR CODE HERE)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(metrics.classification_report(# YOUR CODE HERE))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "knn_conf_matrix = # YOUR CODE HERE\n",
    "disp = # YOUR CODE HERE\n",
    "\n",
    "disp.plot(cmap='ocean');"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
